# UCB1 のリグレット解析テンプレ（確率的K本腕・報酬[0,1]）

## 仮定
- 各腕 i の報酬は [0,1] に入る
- 腕 i を引くたび i.i.d.、平均は μ_i

## 記法
- 最適腕 i*、最適平均 μ* = μ_{i*}
- ギャップ Δ_i = μ* - μ_i
- N_i(t): 時刻 t までの腕 i の試行回数
- \hat μ_i(s): 腕 i を s 回引いたときの経験平均

## アルゴリズム（UCB1）
各時刻 t ≥ 1 で
I_t ∈ argmax_i [ \hat μ_i(N_i(t-1)) + rad(N_i(t-1), t) ]
ただし
rad(s,t) = sqrt( (2 log t) / s ).

## リグレット分解
R_T = Σ_{t=1}^T (μ* - μ_{I_t})
    = Σ_{i:Δ_i>0} Δ_i E[N_i(T)].
よって各劣最適腕 i について E[N_i(T)] を抑えれば十分。

## 補題（Hoeffding）
任意の腕 i と試行回数 s について
P( \hat μ_i(s) - μ_i ≥ ε ) ≤ exp(-2 s ε^2)
P( μ_i - \hat μ_i(s) ≥ ε ) ≤ exp(-2 s ε^2).

ε = rad(s,t)=sqrt((2 log t)/s) と置くと
P( \hat μ_i(s) - μ_i ≥ rad(s,t) ) ≤ t^{-4},
P( μ_i - \hat μ_i(s) ≥ rad(s,t) ) ≤ t^{-4}.

## 良い事象
E_t := ⋂_{i=1}^K ⋂_{s=1}^{t} { | \hat μ_i(s) - μ_i | ≤ rad(s,t) }.
合併界より
P(E_t^c) ≤ Σ_i Σ_s 2 t^{-4} = 2K t · t^{-4} = 2K t^{-3}.
よって Σ_{t=1}^∞ P(E_t^c) < ∞（悪い事象の総寄与は定数）。

## 劣最適腕の回数上界（pull counting）
劣最適腕 i（Δ_i>0）を固定。
m_i := ceil( (8 log T) / Δ_i^2 ) と定義。

主張：E_t が成立し、かつ N_i(t-1) ≥ m_i なら、時刻 t に腕 i は選ばれない。

証明スケッチ：
もし i が選ばれたなら UCB_i(t) ≥ UCB_{i*}(t)。
E_t の下で
UCB_i(t) ≤ μ_i + 2 rad(N_i(t-1), t),
UCB_{i*}(t) ≥ μ*.
よって選択は
μ_i + 2 rad(N_i,t) ≥ μ*
⇒ 2 rad(N_i,t) ≥ Δ_i
を含意する。
一方 N_i ≥ m_i なら（t ≤ T を使って）
2 rad(N_i,t) ≤ 2 sqrt( (2 log T)/m_i ) ≤ Δ_i
となり矛盾。

従って、m_i 回を超えて腕 i が引かれるのは悪い事象 E_t^c のときだけ。

## 期待値評価
N_i(T) ≤ m_i + Σ_{t=1}^T 1{ I_t=i かつ E_t^c }.
期待値を取って
E[N_i(T)] ≤ m_i + Σ_{t=1}^T P(E_t^c)
         ≤ ceil((8 log T)/Δ_i^2) + O(1).

## 結論（リグレット上界）
R_T = Σ_{i:Δ_i>0} Δ_i E[N_i(T)]
≤ Σ_{i:Δ_i>0} ( (8 log T)/Δ_i + O(Δ_i) ).
